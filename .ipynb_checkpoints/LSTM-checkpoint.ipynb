{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import nbimporter\n",
    "from data_pipeline import FetchFinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")    \n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchFinancials(object):\n",
    "  def __init__(self, assets, dependent):\n",
    "    \"\"\"\n",
    "      Yahoo! Finance Data\n",
    "      \n",
    "      Date\tOpen\tHigh\tLow\tClose*\tAdj Close**\tVolumen  \n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.assets = assets\n",
    "    self.dependent = dependent\n",
    "    self.dataframes = []\n",
    "  def _fetch(self):\n",
    "    \"\"\"\n",
    "      Fetch Data Twice Every 30 seconds\n",
    "      \n",
    "      Returns:\n",
    "        data: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # GRAB DATA\n",
    "    for _ticker in self.assets:\n",
    "      time.sleep(1)\n",
    "      try:\n",
    "        ticker = yf.Ticker(_ticker)\n",
    "\n",
    "        # Historical Market Data\n",
    "        result = msft.history(period=\"max\")\n",
    "\n",
    "        for _val in [i for i in result.columns.tolist() if i not in 'Date']:\n",
    "          result.rename(columns={_val: f'{_ticker}_{_val}'}, inplace=True)\n",
    "          \n",
    "\n",
    "        self.dataframes.append(result)\n",
    "      except:\n",
    "        print(f\"{_ticker}: ERROR\")\n",
    "      \n",
    "    # Outer Join on Date\n",
    "    data = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), self.dataframes)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "#   def _continuous_fetch(self, interval):\n",
    "#     \"\"\"\n",
    "#       Continuous Fetching of Data using Threading\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __continuous_fetch():\n",
    "#       threading.Timer(30.0, self._continuous_fetch).start()\n",
    "#       self.data = self._fetch()\n",
    "      \n",
    "#     __continuous_fetch()\n",
    "    \n",
    "  def _calculate_technical_analysis_indicators(self, dataset):\n",
    "    dataset.rename(columns={self.dependent: 'price'}, inplace=True)\n",
    "    \n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset['ma7'] = dataset['price'].rolling(window=7).mean()\n",
    "    dataset['ma21'] = dataset['price'].rolling(window=21).mean()\n",
    "\n",
    "    # Create MACD\n",
    "    dataset['26ema'] = dataset['price'].ewm(span=26).mean()\n",
    "    dataset['12ema'] = dataset['price'].ewm(span=12).mean()\n",
    "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "\n",
    "    # Create Bollinger Bands\n",
    "    dataset['20sd'] = dataset['price'].rolling(window=20).std()\n",
    "    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
    "    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
    "\n",
    "    # Create Exponential moving average\n",
    "    dataset['ema'] = dataset['price'].ewm(com=0.5).mean()\n",
    "\n",
    "    # Create Momentum\n",
    "    dataset['momentum'] = dataset['price']-1\n",
    "\n",
    "    dataset['log_momentum'] = np.log1p(dataset['price'])\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "  def _clean_data(self, dataset):\n",
    "    \"\"\"\n",
    "      Scales Data (-1,1)\n",
    "\n",
    "      Args:\n",
    "        data (pd.DataFrame())\n",
    "\n",
    "      Returns:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    dataset = self._calculate_technical_analysis_indicators(dataset)\n",
    "    \n",
    "    minimum=min(dataset.index).date()\n",
    "    maximum=max(dataset.index).date()\n",
    "\n",
    "    idx = pd.date_range(minimum,maximum)\n",
    "    dataset = dataset.reindex(idx, fill_value=np.nan)\n",
    "\n",
    "    for val in dataset.columns.tolist() if val not in ['price']:\n",
    "      dataset[val].interpolate(method='linear', inplace=True)\n",
    "      scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "      dataset[val] = scaler.fit_transform(dataset[val].values.reshape(-1,1))\n",
    "      \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_assets = {\n",
    "  'JPMorgan': 'JPM',\n",
    "  'Goldman Sachs': 'GS',\n",
    "  'Morgan Stanley': 'MS',\n",
    "  'Wells Fargo': 'WFC',\n",
    "  'Bank of America': 'BCS',\n",
    "  'Barclays': 'BCS',\n",
    "  'Deutche Bank': 'DB',\n",
    "  'Citigroup': 'C',\n",
    "  'Credit Suisse': 'DHY',\n",
    "  'UBS Group': 'UBS',\n",
    "  'HSBC Holdings': 'HSBC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Backtest\n",
    "![title](data/time_series_split.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = list(correlated_assets.values())\n",
    "\n",
    "grab_data = FetchFinancials(assets, 'JPM_Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grab_data._fetch()\n",
    "data = grab_data._calculate_technical_analysis_indicators(data)\n",
    "data = grab_data._clean_data(data)\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "    super(LSTM, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)    \n",
    "  def forward(self, x):\n",
    "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "    out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "    out = self.fc(out[:, -1, :]) \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_charts(original,predict,hist):\n",
    "  fig = plt.figure()\n",
    "  fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  ax = sns.lineplot(x = original.index, y = original[0], label=\"Data\", color='royalblue')\n",
    "  ax = sns.lineplot(x = predict.index, y = predict[0], label=\"Training Prediction (LSTM)\", color='tomato')\n",
    "  ax.set_title('Stock price', size = 14, fontweight='bold')\n",
    "  ax.set_xlabel(\"Days\", size = 14)\n",
    "  ax.set_ylabel(\"Cost (USD)\", size = 14)\n",
    "  ax.set_xticklabels('', size=10)\n",
    "\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  ax = sns.lineplot(data=hist, color='royalblue')\n",
    "  ax.set_xlabel(\"Epoch\", size = 14)\n",
    "  ax.set_ylabel(\"Loss\", size = 14)\n",
    "  ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\n",
    "  fig.set_figheight(6)\n",
    "  fig.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics(x_test,y_train,y_train_pred,y_test):\n",
    "  y_test_pred = model(x_test)\n",
    "\n",
    "  y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "  y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "  y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "  y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "\n",
    "\n",
    "  train_score = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "#   print(f'Train Score: {train_score} RMSE')\n",
    "  test_score = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "#   print(f'Test Score: {test_score} RMSE')\n",
    "  return train_score, test_score, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(scaler,y, train_index,test_index):\n",
    "  trainPlot = y.iloc[train_index]\n",
    "  testPlot = y.iloc[test_index]\n",
    "\n",
    "  original = scaler.inverse_transform(y['price'].values.reshape(-1,1))\n",
    "\n",
    "  breakpoint()\n",
    "  predictions = np.append(trainPlot, testPlot, axis=1)\n",
    "  predictions = np.append(predictions, original, axis=1)\n",
    "  result = pd.DataFrame(predictions)\n",
    "\n",
    "  plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "  for i, col in enumerate(result.columns):\n",
    "    result[col].plot()\n",
    "\n",
    "  plt.title('LSTM Predictions')\n",
    "\n",
    "  plt.xticks(rotation=70)\n",
    "  plt.legend(['Train Prediction', 'Test Prediction', 'Ground Truth'])\n",
    "  plt.xlabel(\"Days\")\n",
    "  plt.ylabel(\"USD ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in data.columns.tolist():\n",
    "  if 'Splits' in val:\n",
    "    data=data.drop(val,axis=1)\n",
    "  if 'Dividends' in val:\n",
    "    data=data.drop(val,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)\n",
    "X,y=data.drop('price',axis=1),data[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(max_train_size=1000,n_splits=10)\n",
    "\n",
    "\n",
    "tr_list, test_list = [],[]\n",
    "\n",
    "for train_index, test_index in tqdm(tscv.split(X),total=10):  \n",
    "  _y = y.copy()\n",
    "  scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "  _y['price'] = scaler.fit_transform(_y['price'].values.reshape(-1,1))\n",
    "  \n",
    "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  X_train, X_test = np.array(X.iloc[train_index].values), np.array(X.iloc[test_index].values)\n",
    "  y_train, y_test = np.array(_y.iloc[train_index].values), np.array(_y.iloc[test_index].values)\n",
    "\n",
    "  \n",
    "  X_train = torch.from_numpy(X_train).type(torch.Tensor).unsqueeze(-1)\n",
    "  X_test = torch.from_numpy(X_test).type(torch.Tensor).unsqueeze(-1)\n",
    "  _y_train = y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "  y_train = _y_train.unsqueeze(-1)\n",
    "  _y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "  y_test = _y_test.unsqueeze(-1)\n",
    "  \n",
    "#   breakpoint()\n",
    "  \n",
    "  hist = np.zeros(num_epochs)\n",
    "  start_time = time.time()\n",
    "  lstm = []\n",
    "  \n",
    "  \n",
    "  input_dim = 1\n",
    "  hidden_dim = 32\n",
    "  num_layers = 4\n",
    "  output_dim = 1\n",
    "  num_epochs = 50\n",
    "\n",
    "  model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "  criterion = torch.nn.MSELoss()\n",
    "  optimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "  \n",
    "\n",
    "\n",
    "  for t in range(num_epochs):\n",
    "    y_train_pred = model(X_train)    \n",
    "    loss = criterion(y_train_pred, y_train)\n",
    "#     print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "  training_time = time.time()-start_time\n",
    "#   print(\"Training time: {}\".format(training_time))\n",
    "  \n",
    "  predict = pd.DataFrame(scaler.inverse_transform(y_train_pred.detach().numpy()))\n",
    "  original = pd.DataFrame(scaler.inverse_transform(_y_train.detach().numpy()))\n",
    "  \n",
    "  \n",
    "#   plot_charts(original,predict,hist)\n",
    "  \n",
    "  #append train and test scores to list\n",
    "  train_score, test_score, y_test_pred = return_metrics(X_test,_y_train,y_train_pred,_y_test)\n",
    "  tr_list.append(train_score); test_list.append(test_score)\n",
    "  \n",
    "#   plot_predictions(scaler,_y, train_index,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train MSE: {sum(tr_list)/len(tr_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test MSE: {sum(test_list)/len(test_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
