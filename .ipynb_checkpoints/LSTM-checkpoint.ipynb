{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3242 entries, 0 to 3241\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   price   3242 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 25.5 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"jpm_daily_close.csv\",index_col=0)\n",
    "df=df.dropna().reset_index(drop=True)\n",
    "price = df[['price']]\n",
    "price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brian\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "price['price'] = scaler.fit_transform(price['price'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_data(stock, lookback):\n",
    "  original_data = stock.to_numpy()\n",
    "  data = []\n",
    "\n",
    "  for index in range(len(original_data) - lookback): \n",
    "      data.append(original_data[index: index + lookback])\n",
    "\n",
    "  data = np.array(data);\n",
    "  test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "  train_set_size = data.shape[0] - (test_set_size);\n",
    "\n",
    "  x_train = data[:train_set_size,:-1,:]\n",
    "  y_train = data[:train_set_size,-1,:]\n",
    "\n",
    "  x_test = data[train_set_size:,:-1]\n",
    "  y_test = data[train_set_size:,-1,:]\n",
    "\n",
    "\n",
    "  x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "  x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "  y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "  y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "  \n",
    "  return [x_train, y_train_lstm, x_test, y_test_lstm]\n",
    "\n",
    "lookback = 20\n",
    "x_train, y_train_lstm, x_test, y_test_lstm = torch_data(price, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "    super(LSTM, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)    \n",
    "  def forward(self, x):\n",
    "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "    out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "    out = self.fc(out[:, -1, :]) \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.2508045732975006\n",
      "Epoch  1 MSE:  0.1962074488401413\n",
      "Epoch  2 MSE:  0.16487041115760803\n",
      "Epoch  3 MSE:  0.15975993871688843\n",
      "Epoch  4 MSE:  0.13613231480121613\n",
      "Epoch  5 MSE:  0.11246677488088608\n",
      "Epoch  6 MSE:  0.08796907961368561\n",
      "Epoch  7 MSE:  0.03813082352280617\n",
      "Epoch  8 MSE:  0.09727898240089417\n",
      "Epoch  9 MSE:  0.02560346946120262\n",
      "Epoch  10 MSE:  0.07036755979061127\n",
      "Epoch  11 MSE:  0.052010368555784225\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "hist = np.zeros(num_epochs)\n",
    "start_time = time.time()\n",
    "lstm = []\n",
    "for t in range(num_epochs):\n",
    "  y_train_pred = model(x_train)    \n",
    "  loss = criterion(y_train_pred, y_train_lstm)\n",
    "  print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "  hist[t] = loss.item()    \n",
    "  optimiser.zero_grad()\n",
    "  loss.backward()\n",
    "  optimiser.step()\n",
    "    \n",
    "training_time = time.time()-start_time\n",
    "print(\"Training time: {}\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(scaler.inverse_transform(y_train_pred.detach().numpy()))\n",
    "original = pd.DataFrame(scaler.inverse_transform(y_train_lstm.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")    \n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.lineplot(x = original.index, y = original[0], label=\"Data\", color='royalblue')\n",
    "ax = sns.lineplot(x = predict.index, y = predict[0], label=\"Training Prediction (LSTM)\", color='tomato')\n",
    "ax.set_title('Stock price', size = 14, fontweight='bold')\n",
    "ax.set_xlabel(\"Days\", size = 14)\n",
    "ax.set_ylabel(\"Cost (USD)\", size = 14)\n",
    "ax.set_xticklabels('', size=10)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.lineplot(data=hist, color='royalblue')\n",
    "ax.set_xlabel(\"Epoch\", size = 14)\n",
    "ax.set_ylabel(\"Loss\", size = 14)\n",
    "ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions\n",
    "y_test_pred = model(x_test)\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(y_train_lstm.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test_lstm.detach().numpy())\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "lstm.append(trainScore)\n",
    "lstm.append(testScore)\n",
    "lstm.append(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(price)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lookback:len(y_train_pred)+lookback, :] = y_train_pred\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(price)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(y_train_pred)+lookback-1:len(price)-1, :] = y_test_pred\n",
    "\n",
    "original = scaler.inverse_transform(price['price'].values.reshape(-1,1))\n",
    "\n",
    "predictions = np.append(trainPredictPlot, testPredictPlot, axis=1)\n",
    "predictions = np.append(predictions, original, axis=1)\n",
    "result = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "for i, col in enumerate(result.columns):\n",
    "    result[col].plot()\n",
    "\n",
    "plt.title('LSTM Predictions')\n",
    "\n",
    "plt.xticks(rotation=70)\n",
    "plt.legend(['Train Prediction', 'Test Prediction', 'Ground Truth'])\n",
    "\n",
    "#Saving the graph into a JPG file\n",
    "# plt.savefig('pic.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
